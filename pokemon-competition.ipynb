{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644d1959-9e40-45e6-8d3d-1ff3403415f3",
   "metadata": {},
   "source": [
    "# Pokémon competition\n",
    "\n",
    "In this notebook you have to provide the best pipeline that you have found to predict Pokémon battles.\n",
    "\n",
    "At the end you will have to generate a set of predictions over the unlabeled data `data.hidden` and `data_inverse.hidden`. In these unlabeled dataset you will find all the Pokémon battles that we will be performing in some *fictional* Pokémon competition, so we do not know the outcome of these battles right now!\n",
    "\n",
    "Remember to use all the tools that we have seen in class to evaluate and fine-tune your pipeline.\n",
    "\n",
    "*Gotta Predict 'Em All!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654a998-6d49-4762-840d-9caab969e502",
   "metadata": {},
   "source": [
    "Paste here your pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3601b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas\n",
    "from sklearn.impute import KNNImputer\n",
    "from pathlib import Path\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "__wd__ = Path(\"__file__\").resolve().parent\n",
    "datasets_path = __wd__ / \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c7aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(dataset):\n",
    "    return dataset.drop(\"Wins\", axis=1), dataset[\"Wins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_df = pandas.read_csv(datasets_path / \"data.train\", index_col=0)\n",
    "\n",
    "processing_df['Wins'] = processing_df['Wins'].astype('Int64')\n",
    "processing_df = processing_df.drop(columns=['Legendary', 'Legendary__other','Generation','Generation__other','Type 2','Type 2__other'])\n",
    "\n",
    "cat = ['Name','Name__other','Type 1','Type 1__other']\n",
    "num = ['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed','HP__other', 'Attack__other', 'Defense__other', 'Sp. Atk__other', 'Sp. Def__other', 'Speed__other']\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"encode\", ColumnTransformer(transformers=[\n",
    "            (\"cat_name\", OneHotEncoder(sparse=False, handle_unknown = 'ignore'), cat)\n",
    "        ],remainder='passthrough')),\n",
    "        (\"imputer\", KNNImputer(n_neighbors=1)),\n",
    "        (\"classifier\", GaussianNB())\n",
    "])\n",
    "\n",
    "X, y = get_Xy(processing_df) # X = features , y = target (Win/Loss)\n",
    "y = y.astype('int')\n",
    "\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f8592",
   "metadata": {},
   "source": [
    "**We change the code below because it is unique way that we found to use our pipeline without errors.** It is because we don't find the correct way to reduce the dataset dimensionality using a pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4ab623-dc53-4b71-8bd4-88db538ca049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Do not change this code\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "import pandas\n",
    "from pathlib import Path\n",
    "\n",
    "__wd__ = Path(\"__file__\").resolve().parent\n",
    "datasets_path = __wd__ / \"datasets\"\n",
    "\n",
    "tournament = pandas.read_csv(datasets_path / \"data.hidden\",index_col=0)\n",
    "tournament.drop(columns=['Legendary', 'Legendary__other','Generation','Generation__other','Type 2','Type 2__other'],inplace=True)\n",
    "\n",
    "tournament_inverse = pandas.read_csv(datasets_path / \"data_inverse.hidden\",index_col=0)\n",
    "tournament_inverse.drop(columns=['Legendary', 'Legendary__other','Generation','Generation__other','Type 2','Type 2__other'],inplace=True)\n",
    "\n",
    "y_predicted = pipeline.predict(tournament)\n",
    "y_inverse_predicted = pipeline.predict(tournament_inverse)\n",
    "\n",
    "y_predicted.tofile(\"predicted.csv\", sep=\",\")\n",
    "y_inverse_predicted.tofile(\"predicted_inverse.csv\", sep=\",\")\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Do not change this code\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
