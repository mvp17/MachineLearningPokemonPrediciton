{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5100e620-aba9-4f0f-93bc-cab59a4a4026",
   "metadata": {},
   "source": [
    "# Assignment 2 - Basic Machine Learning to predict Pokémon battles results\n",
    "\n",
    "([From Wikipedia](https://en.wikipedia.org/wiki/Pok%C3%A9mon)) *Pokémon is a Japanese media franchise managed by The Pokémon Company, a company founded by Nintendo, Game Freak, and Creatures. The franchise was created by Satoshi Tajiri in 1996,[4] and is centered on fictional creatures called \"Pokémon\". In Pokémon, humans, known as Pokémon Trainers, catch and train Pokémon to battle other Pokémon for sport.*\n",
    "\n",
    "In this assignment we present you a dataset with the results of several Pokémon battles.\n",
    "\n",
    "Your objective will be to produce a ML model that can predict the outcomes of any Pokémon battle.\n",
    "\n",
    "At first, in this notebook, you will apply some of the basic ML approaches that we have seen in class. At this point you can also work with the *small* versions of the dataset if you want.\n",
    "\n",
    "Later, on the `pokemon-competition.ipynb` notebook, you will train a model using all the data that will be used to predict *real* Pokémon battles.\n",
    "\n",
    "**Dataset Description**\n",
    "\n",
    "Within the `datasets.zip` file that you can download from the virtual campus, you will find the following datasets:\n",
    "\n",
    "- data.train -> Full data available to train the models\n",
    "- data_inverse.train -> Same data as data.train but each combat is seen from the other player's perspective (i.e. pokemon1 becomes pokemon2 and viceversa)\n",
    "- small.train -> Subsample of data.train to allow fast prototyping\n",
    "- small_inverse.train -> Subsample of data_inverse.train to allow fast prototyping\n",
    "- data.hidden -> Dataset with no label available\n",
    "- data_inverse.hidden -> Same as data.hidden but the pokemons are inverted\n",
    "\n",
    "The datasets *.hidden are the ones used to get the tournament score,\n",
    "so the true label is unknown. All the other datasets are available to\n",
    "you to use however you want.\n",
    "\n",
    "*Gotta Train 'Em All!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4817b09-c29c-48cb-9573-2b57f1eb828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas\n",
    "\n",
    "__wd__ = Path(\"__file__\").resolve().parent\n",
    "datasets_path = __wd__ / \"datasets\"\n",
    "\n",
    "data = pandas.read_csv(datasets_path / \"data.train\", index_col=0)\n",
    "inverse_data = pandas.read_csv(datasets_path / \"data.train\", index_col=0)\n",
    "\n",
    "def get_Xy(dataset):\n",
    "    return dataset.drop(\"Wins\", axis=1), dataset[\"Wins\"]\n",
    "\n",
    "X, y = get_Xy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41f9e74-4521-413c-9f77-ed70e05b8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your imports here\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44123cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional settings\n",
    "pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028a1d7-7aac-4606-b742-640fc4aefe25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1 - Analyze the dataset (2 points)\n",
    "The first step of any ML process is to know the data we are dealing with. In this part, you have to analyze the dataset and answer the questions below.\n",
    "\n",
    "1. Which features are categorical? Which are continuous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062ac0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40000 entries, 39087 to 15795\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Name               36006 non-null  object \n",
      " 1   Type 1             36026 non-null  object \n",
      " 2   Type 2             19465 non-null  object \n",
      " 3   HP                 35994 non-null  float64\n",
      " 4   Attack             36103 non-null  float64\n",
      " 5   Defense            35966 non-null  float64\n",
      " 6   Sp. Atk            36080 non-null  float64\n",
      " 7   Sp. Def            36018 non-null  float64\n",
      " 8   Speed              36028 non-null  float64\n",
      " 9   Generation         36007 non-null  float64\n",
      " 10  Legendary          36019 non-null  object \n",
      " 11  Name__other        36037 non-null  object \n",
      " 12  Type 1__other      35990 non-null  object \n",
      " 13  Type 2__other      19406 non-null  object \n",
      " 14  HP__other          35895 non-null  float64\n",
      " 15  Attack__other      36005 non-null  float64\n",
      " 16  Defense__other     35984 non-null  float64\n",
      " 17  Sp. Atk__other     35904 non-null  float64\n",
      " 18  Sp. Def__other     35995 non-null  float64\n",
      " 19  Speed__other       35956 non-null  float64\n",
      " 20  Generation__other  36014 non-null  float64\n",
      " 21  Legendary__other   36018 non-null  object \n",
      " 22  Wins               40000 non-null  bool   \n",
      "dtypes: bool(1), float64(14), object(8)\n",
      "memory usage: 7.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>Name__other</th>\n",
       "      <th>Type 1__other</th>\n",
       "      <th>Type 2__other</th>\n",
       "      <th>HP__other</th>\n",
       "      <th>Attack__other</th>\n",
       "      <th>Defense__other</th>\n",
       "      <th>Sp. Atk__other</th>\n",
       "      <th>Sp. Def__other</th>\n",
       "      <th>Speed__other</th>\n",
       "      <th>Generation__other</th>\n",
       "      <th>Legendary__other</th>\n",
       "      <th>Wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39087</th>\n",
       "      <td>Karrablast</td>\n",
       "      <td>Bug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Pidove</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30893</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Water</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Tepig</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45278</th>\n",
       "      <td>Mega Manectric</td>\n",
       "      <td>Electric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garbodor</td>\n",
       "      <td>Poison</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>Bouffalant</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Tauros</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>Swablu</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mr. Mime</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Water</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>100.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Prinplup</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23965</th>\n",
       "      <td>Kingler</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45552</th>\n",
       "      <td>Mega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Politoed</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30219</th>\n",
       "      <td>Chespin</td>\n",
       "      <td>Grass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Primal Kyogre</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24079</th>\n",
       "      <td>Volcanion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Water</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Vigoroth</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name    Type 1  Type 2     HP  Attack  Defense  Sp. Atk  \\\n",
       "39087      Karrablast       Bug     NaN   50.0    72.0     39.0     39.0   \n",
       "30893             NaN      Rock   Water   70.0     NaN    125.0    113.0   \n",
       "45278  Mega Manectric  Electric     NaN   70.0    77.0     81.0      NaN   \n",
       "16398      Bouffalant   Psychic     NaN   95.0   121.0      NaN     39.0   \n",
       "13653          Swablu    Normal  Flying   45.0    36.0     58.0     37.0   \n",
       "13748             NaN     Water   Fairy  100.0    57.0     87.0     67.0   \n",
       "23965         Kingler     Water     NaN   55.0   131.0    118.0     51.0   \n",
       "45552    Mega Diancie      Rock   Fairy   50.0   154.0    109.0    164.0   \n",
       "30219         Chespin     Grass     NaN   56.0    54.0     72.0     55.0   \n",
       "24079       Volcanion       NaN   Water   80.0   110.0      NaN    132.0   \n",
       "\n",
       "       Sp. Def  Speed  Generation Legendary    Name__other Type 1__other  \\\n",
       "39087     42.0   55.0         5.0     False         Pidove        Normal   \n",
       "30893     78.0    NaN         1.0     False          Tepig          Fire   \n",
       "45278     91.0  136.0         3.0       NaN       Garbodor        Poison   \n",
       "16398     85.0    NaN         5.0     False         Tauros        Normal   \n",
       "13653     76.0   56.0         3.0     False       Mr. Mime       Psychic   \n",
       "13748     80.0   51.0         2.0      True       Prinplup         Water   \n",
       "23965     54.0   58.0         1.0     False            NaN      Fighting   \n",
       "45552    105.0  106.0         6.0      True       Politoed         Water   \n",
       "30219     50.0    NaN         NaN     False  Primal Kyogre         Water   \n",
       "24079      NaN   74.0         6.0      True       Vigoroth         Fairy   \n",
       "\n",
       "      Type 2__other  HP__other  Attack__other  Defense__other  Sp. Atk__other  \\\n",
       "39087           NaN       50.0           53.0            43.0            47.0   \n",
       "30893           NaN       65.0           64.0             NaN            49.0   \n",
       "45278           NaN        NaN           48.0            78.0             NaN   \n",
       "16398           NaN       75.0          108.0           101.0            39.0   \n",
       "13653         Fairy       40.0           46.0            68.0           108.0   \n",
       "13748           NaN       64.0           66.0            67.0            78.0   \n",
       "23965       Psychic       60.0           61.0            78.0            63.0   \n",
       "45552           NaN       90.0           75.0            76.0            84.0   \n",
       "30219           NaN       92.0          154.0            86.0             NaN   \n",
       "24079           NaN       90.0          117.0            79.0            62.0   \n",
       "\n",
       "       Sp. Def__other  Speed__other  Generation__other Legendary__other   Wins  \n",
       "39087            27.0          40.0                5.0            False   True  \n",
       "30893            41.0          39.0                5.0            False   True  \n",
       "45278            83.0          75.0                5.0            False   True  \n",
       "16398            68.0         106.0                NaN            False  False  \n",
       "13653           123.0          86.0                1.0            False  False  \n",
       "13748            84.0          50.0                4.0            False  False  \n",
       "23965             NaN          78.0                3.0            False  False  \n",
       "45552           102.0          70.0                2.0            False   True  \n",
       "30219           154.0          81.0                3.0             True  False  \n",
       "24079            59.0          44.0                2.0              NaN   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset General Data\n",
    "data.info()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7318af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40000 entries, 39087 to 15795\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Name               36006 non-null  object \n",
      " 1   Type 1             36026 non-null  object \n",
      " 2   Type 2             19465 non-null  object \n",
      " 3   Generation         36007 non-null  float64\n",
      " 4   Legendary          36019 non-null  object \n",
      " 5   Name__other        36037 non-null  object \n",
      " 6   Type 1__other      35990 non-null  object \n",
      " 7   Type 2__other      19406 non-null  object \n",
      " 8   Generation__other  36014 non-null  float64\n",
      " 9   Legendary__other   36018 non-null  object \n",
      " 10  Wins               40000 non-null  bool   \n",
      "dtypes: bool(1), float64(2), object(8)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Categorical Data\n",
    "categorical_df = data[['Name','Type 1','Type 2','Generation','Legendary','Name__other','Type 1__other','Type 2__other','Generation__other','Legendary__other','Wins']]\n",
    "categorical_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956d17ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40000 entries, 39087 to 15795\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   HP              35994 non-null  float64\n",
      " 1   Attack          36103 non-null  float64\n",
      " 2   Defense         35966 non-null  float64\n",
      " 3   Sp. Atk         36080 non-null  float64\n",
      " 4   Sp. Def         36018 non-null  float64\n",
      " 5   Speed           36028 non-null  float64\n",
      " 6   HP__other       35895 non-null  float64\n",
      " 7   Attack__other   36005 non-null  float64\n",
      " 8   Defense__other  35984 non-null  float64\n",
      " 9   Sp. Atk__other  35904 non-null  float64\n",
      " 10  Sp. Def__other  35995 non-null  float64\n",
      " 11  Speed__other    35956 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Continuous Data\n",
    "continuous_df = data[['HP','Attack','Defense','Sp. Atk','Sp. Def','Speed','HP__other','Attack__other','Defense__other','Sp. Atk__other','Sp. Def__other','Speed__other']]\n",
    "continuous_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6fdf6-20ac-4c0c-b0fc-e39941f774cc",
   "metadata": {},
   "source": [
    "2. Observe the distribution of the \"Type 1\" variable. Use a plot to show this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973db97c-436b-480c-924b-76f19f78f619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Type 1'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f024e8b3-590e-4908-8e1e-a77673ec6db2",
   "metadata": {},
   "source": [
    "3. Determine which of the features have missing values. How many missing values there are for each one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02f0dc1e-d1a5-4d06-aaa8-eec8ba0d306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'Type 1',\n",
       " 'Type 2',\n",
       " 'HP',\n",
       " 'Attack',\n",
       " 'Defense',\n",
       " 'Sp. Atk',\n",
       " 'Sp. Def',\n",
       " 'Speed',\n",
       " 'Generation',\n",
       " 'Legendary',\n",
       " 'Name__other',\n",
       " 'Type 1__other',\n",
       " 'Type 2__other',\n",
       " 'HP__other',\n",
       " 'Attack__other',\n",
       " 'Defense__other',\n",
       " 'Sp. Atk__other',\n",
       " 'Sp. Def__other',\n",
       " 'Speed__other',\n",
       " 'Generation__other',\n",
       " 'Legendary__other']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with missing values\n",
    "list(data.columns[data.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "339f3770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  3994\n",
       "Type 1                3974\n",
       "Type 2               20535\n",
       "HP                    4006\n",
       "Attack                3897\n",
       "Defense               4034\n",
       "Sp. Atk               3920\n",
       "Sp. Def               3982\n",
       "Speed                 3972\n",
       "Generation            3993\n",
       "Legendary             3981\n",
       "Name__other           3963\n",
       "Type 1__other         4010\n",
       "Type 2__other        20594\n",
       "HP__other             4105\n",
       "Attack__other         3995\n",
       "Defense__other        4016\n",
       "Sp. Atk__other        4096\n",
       "Sp. Def__other        4005\n",
       "Speed__other          4044\n",
       "Generation__other     3986\n",
       "Legendary__other      3982\n",
       "Wins                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Missing Values for each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f983236-2bf6-495f-adc2-266c0dba82e6",
   "metadata": {},
   "source": [
    "4. Analize the distribution of the target column. Is it balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a253ecaf-ee73-42ce-a8eb-db7d23862356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Wins'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695aecba",
   "metadata": {},
   "source": [
    "As we can see in the bar plot, the target column is well-balanced because all the the different values (in our case true or false) have more or less the same quantity. The distribution of the different values is well equilibrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd9135-71cf-4624-8a35-208a23faaaeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2 - Preprocess the data (3 points)\n",
    "Once we know how the dataset is, we can proceed with the cleaning of the data. This includes:\n",
    "\n",
    "- Select the features that you want to use (p.e. removing too specific features). Explain why each feature is used or discarded.\n",
    "- Impute the missing values. Explain why you use this imputer and not another one. If you use different imputers for different features, explain the reason why you do this.\n",
    "- Encode the values of the features to work with the model you choose. This can be either encoding the categorical values, or discretizing continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29ce154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "processing_df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b943b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "# Drop rows with missing values with too much data is also dangerous. It can \n",
    "# create significant bias by depriving your algorithms of space. This is specially true of classifiers sensitive \n",
    "# to the curse of dimensionality. In our case we start with 40.000 rows and if we clean it, we have more or less\n",
    "# 1400 rows, it means that we lose a lot information.\n",
    "\n",
    "# Encode Categorical Variables: Booleans (False = 0, True = 1) \n",
    "\n",
    "processing_df['Wins'] = processing_df['Wins'].astype('Int64')\n",
    "processing_df['Legendary__other'] = processing_df['Legendary__other'].map({False:0,True:1})\n",
    "processing_df['Legendary'] = processing_df['Legendary'].map({False:0,True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c451051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abomasnow' 'Abra' 'Absol' 'Accelgor' 'Aegislash Blade Forme'\n",
      " 'Aegislash Shield Forme' 'Aerodactyl' 'Aggron' 'Aipom' 'Alakazam']\n",
      "['Bug' 'Dark' 'Dragon' 'Electric' 'Fairy' 'Fighting' 'Fire' 'Flying'\n",
      " 'Ghost' 'Grass']\n"
     ]
    }
   ],
   "source": [
    "# Encode Categorical Data : Strings\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "# https://stackoverflow.com/questions/54444260/labelencoder-that-keeps-missing-values-as-nan\n",
    "\n",
    "label_to_encode_name = ['Name','Name__other']\n",
    "label_to_encode_type = ['Type 1','Type 2','Type 1__other','Type 2__other']\n",
    "\n",
    "label_encoder_name = LabelEncoder()\n",
    "label_encoder_type = LabelEncoder()\n",
    "\n",
    "# Encode Pokemon Names\n",
    "processing_df[label_to_encode_name] = processing_df[label_to_encode_name].apply(lambda series: pandas.Series(\n",
    "    label_encoder_name.fit_transform(series[series.notnull()]),\n",
    "    index=series[series.notnull()].index\n",
    "))\n",
    "\n",
    "# Encode Pokemon Types\n",
    "processing_df[label_to_encode_type] = processing_df[label_to_encode_type].apply(lambda series: pandas.Series(\n",
    "    label_encoder_type.fit_transform(series[series.notnull()]),\n",
    "    index=series[series.notnull()].index\n",
    "))\n",
    "\n",
    "print(label_encoder_name.classes_[:10])\n",
    "print(label_encoder_type.classes_[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cbee6ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>Name__other</th>\n",
       "      <th>Type 1__other</th>\n",
       "      <th>Type 2__other</th>\n",
       "      <th>HP__other</th>\n",
       "      <th>Attack__other</th>\n",
       "      <th>Defense__other</th>\n",
       "      <th>Sp. Atk__other</th>\n",
       "      <th>Sp. Def__other</th>\n",
       "      <th>Speed__other</th>\n",
       "      <th>Generation__other</th>\n",
       "      <th>Legendary__other</th>\n",
       "      <th>Wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>736.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>671.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Type 1  Type 2    HP  Attack  Defense  Sp. Atk  Sp. Def  Speed  \\\n",
       "0  314.0     0.0     1.0  50.0    72.0     39.0     39.0     42.0   55.0   \n",
       "1  736.0    15.0    17.0  70.0    83.0    125.0    113.0     78.0   55.0   \n",
       "2  425.0     3.0     7.0  70.0    77.0     81.0     65.0     91.0  136.0   \n",
       "3   58.0    14.0     7.0  95.0   121.0     75.0     39.0     85.0   94.0   \n",
       "4  671.0    12.0     7.0  45.0    36.0     58.0     37.0     76.0   56.0   \n",
       "\n",
       "   Generation  Legendary  Name__other  Type 1__other  Type 2__other  \\\n",
       "0         5.0        0.0        521.0           12.0            7.0   \n",
       "1         1.0        0.0        689.0            6.0           17.0   \n",
       "2         3.0        0.0        222.0           13.0            7.0   \n",
       "3         5.0        0.0        685.0           12.0           13.0   \n",
       "4         3.0        0.0        470.0           14.0            4.0   \n",
       "\n",
       "   HP__other  Attack__other  Defense__other  Sp. Atk__other  Sp. Def__other  \\\n",
       "0       50.0           53.0            43.0            47.0            27.0   \n",
       "1       65.0           64.0            50.0            49.0            41.0   \n",
       "2       60.0           48.0            78.0           110.0            83.0   \n",
       "3       75.0          108.0           101.0            39.0            68.0   \n",
       "4       40.0           46.0            68.0           108.0           123.0   \n",
       "\n",
       "   Speed__other  Generation__other  Legendary__other  Wins  \n",
       "0          40.0                5.0               0.0   1.0  \n",
       "1          39.0                5.0               0.0   1.0  \n",
       "2          75.0                5.0               0.0   1.0  \n",
       "3         106.0                6.0               0.0   0.0  \n",
       "4          86.0                1.0               0.0   0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputation Data\n",
    "\n",
    "# A) Simple imputation\n",
    "# imp_num = SimpleImputer(strategy='mean')\n",
    "# imp_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# B) Iterative Imputer\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "    \n",
    "# imp_num = IterativeImputer(estimator=RandomForestRegressor(),\n",
    "#                            initial_strategy='mean',\n",
    "#                            max_iter=1, random_state=0)\n",
    "\n",
    "# imp_cat = IterativeImputer(estimator=RandomForestClassifier(), \n",
    "#                            initial_strategy='most_frequent',\n",
    "#                            max_iter=1, random_state=0)\n",
    "\n",
    "# categorical = list(categorical_df.columns)\n",
    "# categorical.remove('Wins')\n",
    "# numerical = continuous_df.columns\n",
    "\n",
    "# processing_df[numerical] = imp_num.fit_transform(processing_df[numerical])\n",
    "# processing_df[categorical] = imp_cat.fit_transform(processing_df[categorical])\n",
    "\n",
    "# C) Impute Missing Values using KNN\n",
    "# Imputation for completing missing values using k-Nearest Neighbors.\n",
    "# https://stackoverflow.com/questions/64900801/implementing-knn-imputation-on-categorical-variables-in-an-sklearn-pipeline\n",
    "# https://towardsdatascience.com/going-beyond-the-simpleimputer-for-missing-data-imputation-dd8ba168d505\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=1) # n_neighbors=1 avoid mean/average values\n",
    "processing_df = knn_imputer.fit_transform(processing_df)\n",
    "processing_df = pandas.DataFrame(processing_df,columns=data.columns)\n",
    "\n",
    "processing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784847c2",
   "metadata": {},
   "source": [
    "IterativeImputer actually builds a regression model iteratively by using subsets of the columns to predict the missing values. kNNImputer is also a multivariate approach however it uses kNN which would average the features based on some distance metric (usually Euclidean).\n",
    "\n",
    "The kNNImputer could do better and could be faster than Iterative Imputer when the dimension of the dataset is high. It is because Iterative Imputer runs regression on a bunch of combinations of many columns then it will take a lot of time.\n",
    "\n",
    "We decide to use KNN imputer because it follows the k-Nearest Neighbors method to replace the missing values in the datasets with the mean value from the parameter ‘n_neighbors’ (we only use one neighbor to avoid the mean values) nearest neighbors found in the training set. By default, it uses a Euclidean distance metric to impute the missing values.\n",
    "\n",
    "One thing to note here is that the KNN Imputer does not recognize text data values, and for this reason we decide to encode data before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e67a470e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Name            40000 non-null  float64\n",
      " 1   Type 1          40000 non-null  float64\n",
      " 2   HP              40000 non-null  float64\n",
      " 3   Attack          40000 non-null  float64\n",
      " 4   Defense         40000 non-null  float64\n",
      " 5   Sp. Atk         40000 non-null  float64\n",
      " 6   Sp. Def         40000 non-null  float64\n",
      " 7   Speed           40000 non-null  float64\n",
      " 8   Name__other     40000 non-null  float64\n",
      " 9   Type 1__other   40000 non-null  float64\n",
      " 10  HP__other       40000 non-null  float64\n",
      " 11  Attack__other   40000 non-null  float64\n",
      " 12  Defense__other  40000 non-null  float64\n",
      " 13  Sp. Atk__other  40000 non-null  float64\n",
      " 14  Sp. Def__other  40000 non-null  float64\n",
      " 15  Speed__other    40000 non-null  float64\n",
      " 16  Wins            40000 non-null  float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 5.2 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Name__other</th>\n",
       "      <th>Type 1__other</th>\n",
       "      <th>HP__other</th>\n",
       "      <th>Attack__other</th>\n",
       "      <th>Defense__other</th>\n",
       "      <th>Sp. Atk__other</th>\n",
       "      <th>Sp. Def__other</th>\n",
       "      <th>Speed__other</th>\n",
       "      <th>Wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>736.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>671.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>258.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>319.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>412.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>740.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>737.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>423.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>317.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>240.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>617.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>338.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Type 1     HP  Attack  Defense  Sp. Atk  Sp. Def  Speed  \\\n",
       "0   314.0     0.0   50.0    72.0     39.0     39.0     42.0   55.0   \n",
       "1   736.0    15.0   70.0    83.0    125.0    113.0     78.0   55.0   \n",
       "2   425.0     3.0   70.0    77.0     81.0     65.0     91.0  136.0   \n",
       "3    58.0    14.0   95.0   121.0     75.0     39.0     85.0   94.0   \n",
       "4   671.0    12.0   45.0    36.0     58.0     37.0     76.0   56.0   \n",
       "5   258.0    17.0  100.0    57.0     87.0     67.0     80.0   51.0   \n",
       "6   319.0    17.0   55.0   131.0    118.0     51.0     54.0   58.0   \n",
       "7   412.0    15.0   50.0   154.0    109.0    164.0    105.0  106.0   \n",
       "8    91.0     9.0   56.0    54.0     72.0     55.0     50.0   61.0   \n",
       "9   740.0     6.0   80.0   110.0     65.0    132.0     91.0   74.0   \n",
       "10  737.0     9.0   91.0    88.0     70.0     87.0    125.0  106.0   \n",
       "11  423.0    12.0   65.0   135.0     94.0     53.0    101.0  135.0   \n",
       "12  317.0    17.0   91.0    68.0     87.0    126.0     93.0  104.0   \n",
       "13  620.0     9.0   75.0    97.0     66.0     99.0     70.0  103.0   \n",
       "14  406.0     0.0   65.0   157.0     84.0     19.0     76.0  144.0   \n",
       "15  160.0    14.0   45.0    30.0     54.0     62.0     49.0   45.0   \n",
       "16  240.0     9.0   60.0    68.0     65.0     86.0     99.0   37.0   \n",
       "17  617.0    11.0   95.0    57.0     83.0    107.0     86.0  106.0   \n",
       "18   37.0    17.0   50.0    47.0     47.0     44.0     31.0   59.0   \n",
       "19  338.0    10.0   89.0   148.0     92.0     96.0     79.0   91.0   \n",
       "\n",
       "    Name__other  Type 1__other  HP__other  Attack__other  Defense__other  \\\n",
       "0         521.0           12.0       50.0           53.0            43.0   \n",
       "1         689.0            6.0       65.0           64.0            50.0   \n",
       "2         222.0           13.0       60.0           48.0            78.0   \n",
       "3         685.0           12.0       75.0          108.0           101.0   \n",
       "4         470.0           14.0       40.0           46.0            68.0   \n",
       "5         540.0           17.0       64.0           66.0            67.0   \n",
       "6         120.0            5.0       60.0           61.0            78.0   \n",
       "7         529.0           17.0       90.0           75.0            76.0   \n",
       "8         538.0           17.0       92.0          154.0            86.0   \n",
       "9         735.0            4.0       90.0          117.0            79.0   \n",
       "10        689.0            6.0       65.0           64.0            36.0   \n",
       "11        200.0            3.0       70.0           56.0            63.0   \n",
       "12        599.0           10.0       35.0           96.0            33.0   \n",
       "13        198.0            9.0       63.0           88.0           126.0   \n",
       "14        597.0           17.0       65.0           59.0            49.0   \n",
       "15        490.0            3.0       30.0           51.0           138.0   \n",
       "16        378.0            9.0       62.0           36.0            71.0   \n",
       "17        417.0           17.0       80.0          121.0            81.0   \n",
       "18        169.0            9.0       50.0           72.0            85.0   \n",
       "19        318.0            9.0       74.0           97.0            90.0   \n",
       "\n",
       "    Sp. Atk__other  Sp. Def__other  Speed__other  Wins  \n",
       "0             47.0            27.0          40.0   1.0  \n",
       "1             49.0            41.0          39.0   1.0  \n",
       "2            110.0            83.0          75.0   1.0  \n",
       "3             39.0            68.0         106.0   0.0  \n",
       "4            108.0           123.0          86.0   0.0  \n",
       "5             78.0            84.0          50.0   0.0  \n",
       "6             63.0            60.0          78.0   0.0  \n",
       "7             84.0           102.0          70.0   1.0  \n",
       "8            180.0           154.0          81.0   0.0  \n",
       "9             62.0            59.0          44.0   1.0  \n",
       "10            42.0            44.0          49.0   1.0  \n",
       "11            79.0            56.0          47.0   1.0  \n",
       "12            28.0            47.0          23.0   1.0  \n",
       "13            52.0           117.0          16.0   0.0  \n",
       "14            49.0            65.0          47.0   1.0  \n",
       "15            42.0            85.0          29.0   1.0  \n",
       "16            65.0            66.0          42.0   0.0  \n",
       "17           124.0            84.0         100.0   0.0  \n",
       "18            33.0            33.0          50.0   1.0  \n",
       "19            92.0            99.0          45.0   1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce dimension of the dataset\n",
    "processing_df = processing_df.drop(columns=['Legendary', 'Legendary__other','Generation','Generation__other','Type 2','Type 2__other'])\n",
    "processing_df.info()\n",
    "processing_df.head(20)\n",
    "\n",
    "# Legendary variable defines the rarity to find this Pokemon. Therefore, doesn't affect the victory of the battle.\n",
    "# Generation variable defines the seasson that the Pokemon appears.\n",
    "# Type_1 of the Pokemon define the weak/strong over the other pokemon type.\n",
    "# Type_2 is descarted because it has 50% missing values\n",
    "# All the continuous variables are important to predict the battle.\n",
    "# Wins variable is obviously required to develop the supervised prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b803e-0f87-41dc-a1a9-a7256fb824ba",
   "metadata": {},
   "source": [
    "## Part 3 - Training your model (3 points)\n",
    "In this part you have to train a **classifier** model to predict if a Pokemon will win or not a battle against another Pokemon. For this, you should explore at least 3 different classifiers.\n",
    "\n",
    "You have to train and evaluate those classifiers using cross-validation in order to select the best one. Then, you should also study the results of the model (overfit, underfit, possible bias...).\n",
    "\n",
    "1. Train (at least) 3 different classifiers\n",
    "2. Evaluate the 3 classifiers using cross-validation. Select the best model according to this metric.\n",
    "3. For the selected model: \n",
    "   1. Get the accuracy for data not seen during the training process\n",
    "   2. Plot the confusion matrix\n",
    "   3. Analize the results of accuracy and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e639d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_Xy(processing_df) # X = features , y = target (Win/Loss)\n",
    "\n",
    "# y = y.astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "187f41ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Scores: [0.760625 0.76875  0.783125 0.73375  0.766875 0.76625  0.753125 0.75\n",
      " 0.755625 0.765   ]\n",
      "\n",
      "0.7603125 accuracy with a standard deviation of 0.012560012191474963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation : https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators\n",
    "\n",
    "# Classifier A: Naive Bayes\n",
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "# https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Cross Validation\n",
    "scores = cross_val_score(gnb, X_train, y_train, cv=10) # 10 Folds\n",
    "print(f\"Naive Bayes Scores: {scores}\\n\")\n",
    "print(f\"{scores.mean()} accuracy with a standard deviation of {scores.std()}\\n\")\n",
    "\n",
    "gnb_y_pred = gnb.fit(X_train, y_train).predict(X_test) # Fit the model &  Predict the response of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d19186",
   "metadata": {},
   "source": [
    "As we can see the results of cross-validation, it shows that this algorithm has overfiting in some cases because it captures some noise that means it \"missed the point\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "546b7ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal Network MLPClassifier Scores: [0.80375  0.811875 0.78125  0.7775   0.78     0.82     0.81875  0.8075\n",
      " 0.816875 0.78    ]\n",
      "\n",
      "0.79975 accuracy with a standard deviation of 0.017043602172076174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier B: Neuronal Network MLPClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(random_state=1, max_iter=300)\n",
    "\n",
    "# Cross Validation\n",
    "scores = cross_val_score(nn, X_train, y_train, cv=10)\n",
    "print(f\"Neuronal Network MLPClassifier Scores: {scores}\\n\")\n",
    "print(f\"{scores.mean()} accuracy with a standard deviation of {scores.std()}\\n\")\n",
    "\n",
    "nn_y_pred = nn.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbed0b6",
   "metadata": {},
   "source": [
    "As we can see the results of cross-validation, it shows that this algorithm has overfiting in some cases because it captures some noise that means it \"missed the point\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab0b82ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors Classification Scores: [0.720625 0.729375 0.743125 0.720625 0.72875  0.721875 0.724375 0.726875\n",
      " 0.720625 0.73375 ]\n",
      "\n",
      "0.7270000000000001 accuracy with a standard deviation of 0.006851094803022379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier C: Nearest Neighbors Classification\n",
    "# https://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Cross Validation\n",
    "scores = cross_val_score(neigh, X_train, y_train, cv=10)\n",
    "print(f\"Nearest Neighbors Classification Scores: {scores}\\n\")\n",
    "print(f\"{scores.mean()} accuracy with a standard deviation of {scores.std()}\\n\")\n",
    "\n",
    "neigh_y_pred = neigh.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d116f68",
   "metadata": {},
   "source": [
    "As we can see the results of cross-validation, it shows that this algorithm has underfiting in some cases because it has high loss for instance in the value 0.70625 to the value 0.66875."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e135a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees Scores: [0.770625 0.75625  0.77875  0.75     0.748125 0.748125 0.739375 0.75125\n",
      " 0.7525   0.779375]\n",
      "\n",
      "0.7574375 accuracy with a standard deviation of 0.013147153922047171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier D: Decision Trees\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Cross Validation\n",
    "scores = cross_val_score(tree, X_train, y_train, cv=10)\n",
    "print(f\"Decision Trees Scores: {scores}\\n\")\n",
    "print(f\"{scores.mean()} accuracy with a standard deviation of {scores.std()}\\n\")\n",
    "\n",
    "tree_y_pred = tree.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ed87c",
   "metadata": {},
   "source": [
    "As we can see the results of cross-validation, it seems that the algorithm doesn't have overfiting and underfiting, it means that the results are keeping similar values, therefore it has a robust fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b11e9",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "According to the cross_val_score the algortihm that has better mean and deviation score is Navie Bayes when we use **\"small.train\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf7c8b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7591666666666667\n"
     ]
    }
   ],
   "source": [
    "# Accuracity\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfaafdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEGCAYAAAAHRgwvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAi50lEQVR4nO3de7xVdZ3/8df7HO4IciduKhppQEppqDk5XirRmsHpp4nVSP0szPHS1C8brSkb++HPabLMEpXMEcfUH5Ym3vCCmuaoiGgiKHISBYS4q8jlwDnnM3+sdWBz2HufdeTsc9nn/Xw81mOv9V3ftdZ3s+HD97u+6/tdigjMzGxPFa1dADOztsoB0sysAAdIM7MCHCDNzApwgDQzK6BTaxegqQb0q4wDRnRu7WJYE7z2Uo/WLoI10SY2rouIge/3+JOO7xnrN9Rmyvv8S9UPRsSE93utUmp3AfKAEZ2Z++CI1i6GNcFJQ8e1dhGsiR6J3725N8ev31DL3Af3y5S3csiSAXtzrVJqdwHSzNq+AOqoa+1i7DUHSDNrdkGwI7I1sdsyB0gzKwnXIM3M8giC2jIYxuwAaWYlUYcDpJnZHgKodYA0M8vPNUgzszwC2OF7kGZmewrCTWwzs7wCatt/fHSANLPml4ykaf8cIM2sBEQtau1C7DUHSDNrdkknjQOkmdkekucgHSDNzPKqcw3SzGxPrkGamRUQiNoyeKOLA6SZlYSb2GZmeQRie1S2djH2WvuvA5tZm5M8KF6RaclC0jclvSxpoaR/TtP6SXpY0pL0s29O/kskVUlaLOmknPTDJS1I910tqWg11wHSzEqiNn1YvLGlMZLGAl8HxgOHAZ+TNAq4GJgTEaOAOek2kkYDk4AxwARgmqT66uy1wBRgVLoUfZuiA6SZNbsIURsVmZYMPgw8ExFbIqIG+CPwD8BEYEaaZwZwaro+Ebg9IqojYilQBYyXNAToHRFPR0QAN+cck5cDpJmVRB3KtGTwMnCspP6SegCnACOAwRGxCiD9HJTmHwYszzl+RZo2LF1vmF6QO2nMrNklnTSZw8sASfNytqdHxPSd54p4RdK/Aw8D7wF/BmqKnC9f1I0i6QU5QJpZs6vvpMloXUQcUfR8Eb8BfgMg6XKS2t9qSUMiYlXafF6TZl9BUsOsNxxYmaYPz5NekJvYZlYStaFMSxaSBqWf+wGfB24DZgGT0yyTgbvT9VnAJEldJY0k6YyZmzbDN0k6Ku29PivnmLxcgzSzZleCkTS/l9Qf2AGcFxEbJV0BzJR0NrAMOB0gIhZKmgksImmKnxcRtel5zgVuAroDD6RLQQ6QZlYSddl6qDOJiE/mSVsPnFgg/1Rgap70ecDYrNd1gDSzZpdMVtH+7+A5QJpZswvEjjIYaugAaWbNLoKsD4G3aQ6QZlYCmR8Cb9McIM2s2QWuQZqZFeROGjOzPAJ5wlwzs3yS1762//DS/r+BmbVB2eZ6bOscIM2s2QXNO5KmtThAmllJuAZpZpZHhFyDNDPLJ+mk8VBDM7M85AfFzczySTppfA/SzCwvj6QxM8vDI2nMzIpowku72iwHSDNrdhGwo84B0sxsD0kT2wHSzCwvj6Sxou66YQAP/LY/EXDylzbw+a+vZeo5+7PiL90A2PxuJT1713LtI4t59M6+3DFt0M5jl77SjWsefI2Dxm7le188kA1rOlNbA2OP3Mz5l6+gsv0/g9vmDBy6nYt+sYy+g2qIOrj/lv784TcDOXDMVi68YgVdutVRWyN+dclwFr/Yg4PHbeGb/7EcAAH/deUH+O/Z++52zh/dtJQh+23nnBMOboVv1Hr8mE8GkiYAvwAqgRsi4ooG+5XuPwXYAnwlIuaXskwt5Y1Xu/HAb/tz9X2v0blL8L0vHsSRJ77D969/c2ee6/9tKD17Ja/rPeHzGznh8xuBJDj+6KsjOWjsVgC+f/0b9OxVRwT8+OsH8OQ9fTju1Ldb/DuVu9oaMf2yoVQt6EH3nrX8avZrzH+iF1/715Xc8rPBzHusNx8/4V3O/teVfPe0D/LG4m6cP+FD1NWKfoN2cO0jr/HMw72pq00CwzEnv822ze2/mfn+lEcTu2TfQFIlcA1wMjAaOFPS6AbZTgZGpcsU4NpSlaelLVvSlQ9/bAvdegSVneDQo9/jqQf67NwfAU/M6sPxp27c49jH/tCX43LSe/aqA6C2Bmq2izJoubRJG9Z0pmpBDwC2bq5keVU3BgzZQQQ7/yPr2buWDas7A1C9tWJnMOzcNfkPrF63HrV8/py13HrV4Jb9Em1IXfpemsaWLCR9S9JCSS9Luk1SN0n9JD0saUn62Tcn/yWSqiQtlnRSTvrhkhak+65OK2kFlTLEjweqIuL1iNgO3A5MbJBnInBzJJ4B+kgaUsIytZgDDtnGgmd78u6GSrZtEc892pu1Kzvv3P/ysz3pO7CGYQdu3+PYJHC+vVva9848kDMOHUv3fer45Ofe3uMYa16Dh2/noLFbeXV+D6774TC+9oNV3DJvEV//wUpuvHzXX9GDP7qZ6Y+9yvWPvsbV/zJ8Z8Cc/N2/8vvrBlG9tf3Xot6PpBe7MtPSGEnDgAuBIyJiLEmLdBJwMTAnIkYBc9Jt0orYJGAMMAGYllbYIKmETWFXxWxCsWuX8tcbBizP2V6RpjU1D5KmSJonad7a9bXNXtBS2G9UNV/4pzVcMukgvv+lgxg5eiuVnXZVMRrWEuu9Or8HXbvXccAh23ZLv/y217nthYXs2C5e/NM+JS9/R9atRy0/uOENrvvhULa8V8nnJq/n+kuH8uUjRnP9j4bx7Z/t+iu7+IWeTDn+EC44eRSTLlhN5651HDhmK0NHbt/jfmRHUv+geJYlo05Ad0mdgB7ASpIK1ox0/wzg1HR9InB7RFRHxFKgChifVr56R8TTERHAzTnH5FXKAJnvm8f7yENETI+IIyLiiIH920/vxIQvbuCah17jyruq6NWnlmEjq4GkqfzU/fvyt3//9h7HPH53n7yBE6BLt+Doz7zD0w923H94pVbZKfjBDW/w6J19d94S+fTpG/jT/cmf+RP37MuHxm3Z47jlVd3YtqWCAw7exujDNzPqI1uY8ewirvxDFcMOrOYnv6tqya/RJjShiT2gvgKULlNyzxMRbwE/BZYBq4B3IuIhYHBErErzrALqezkLVbyGpesN0wsqZSfNCmBEzvZwkqjf1Dzt1tvrOtFnQA1rVnTmqfv35ap7lgAw/8lejPhgNQOH7tgtf10dPHlvH356565/TFs3V7DlvQr6D66htgbmzunN2CM3t+j36DiCb1+5nOVLunHn9IE7U9ev7syhR2/mpaf3YdzfvMfKpV0BGDyimrUru1BXKwYN287wg6pZvaILS17qwb03D0jyDN/OZTcv5bunfbBVvlFraWIv9rqIOKLQzvTe4kRgJPA2cIekLxc5X6GKV6YKWa5SBsjngFGSRgJvkdwT+GKDPLOA8yXdDhxJ8j/DqhKWqUVd9rUD2LSxE5Wdg/MvX0GvPsntgT/enb95veCZfRgwZAdD9t91X3Lblgp+9JUD2bFd1NbCuGPe43NnrWux79CRjBm/mU+dvpHXF3Vj2sOLAfjP/zeEqy4azrmXraSyMtheXcFVFw0HYOz4zZxx/lJqakRdnfjl94bz7gY/OVevGXuxPwUsjYi1AJLuBD4BrJY0JCJWpc3nNWn+QhWvFel6w/SCFFE0gO4VSacAV5HcVL0xIqZK+gZARFyX9iD9iuRG6RbgqxExr9g5jzisW8x9cESxLNbGnDR0XGsXwZrokfjd88VqdY3pe8igOOHG0zLlvfOYa4teS9KRwI3Ax4GtwE3APGA/YH1EXCHpYqBfRHxX0hjgVpKO4qEkHTijIqJW0nPABcCzwP3ALyPi/kLXLul/d+mF72+Qdl3OegDnlbIMZtY6mutB8Yh4VtLvgPlADfACMB3YB5gp6WyS+5Onp/kXSpoJLErznxcR9b2755IE2O7AA+lSkNsDZtbsmnskTURcClzaILkaOLFA/qnA1Dzp84CxWa/rAGlmJeGhhmZmeXjCXDOzIrIOI2zLHCDNrNlFQI0nzDUzy89NbDOzPHwP0sysiHCANDPLz500ZmZ5RPgepJlZAaLWvdhmZvn5HqSZWR5+q6GZWSEBJZxJscU4QJpZSbgX28wsj3AnjZlZYW5im5kV4F5sM7M8IhwgzcwK8mM+ZmYF+B6kmVkegahzL7aZWX5lUIGk/Yd4M2t70k6aLEtjJB0s6cWc5V1J/yypn6SHJS1JP/vmHHOJpCpJiyWdlJN+uKQF6b6rJRUtgAOkmZVGZFwaO03E4ogYFxHjgMOBLcBdwMXAnIgYBcxJt5E0GpgEjAEmANMkVaanuxaYAoxKlwnFru0AaWYl0Vw1yAZOBP4SEW8CE4EZafoM4NR0fSJwe0RUR8RSoAoYL2kI0Dsino6IAG7OOSavgvcgJf2SIvE9Ii7M9HXMrMMJoK4uc/AbIGlezvb0iJheIO8k4LZ0fXBErAKIiFWSBqXpw4Bnco5ZkabtSNcbphdUrJNmXpF9ZmaFBZC9drguIo5oLJOkLsDfA5c0lrVAiQqlF1QwQEbEjNxtST0jYnMjBTMzA0ryHOTJwPyIWJ1ur5Y0JK09DgHWpOkrgBE5xw0HVqbpw/OkF9ToPUhJR0taBLySbh8maVqWb2NmHVgzddLkOJNdzWuAWcDkdH0ycHdO+iRJXSWNJOmMmZs2xzdJOirtvT4r55i8snTSXAWcBKwHiIg/A8dm+jpm1kFl66DJ2kkjqQfwaeDOnOQrgE9LWpLuuwIgIhYCM4FFwGzgvIioTY85F7iBpOPmL8ADxa6b6UHxiFje4HGh2kJ5zcyAZn1SPCK2AP0bpK0n6dXOl38qMDVP+jxgbNbrZgmQyyV9Aoj0JumFpM1tM7O8AiJ7L3ablaWJ/Q3gPJLu8LeAcem2mVkRyri0XY3WICNiHfClFiiLmZWTMhiMnaUX+0BJ90haK2mNpLslHdgShTOzdqz5e7FbXJYm9q0kPUJDgKHAHeze1W5mtrv6B8WzLG1YlgCpiPiviKhJl1to83HfzFpbRLalLSs2FrtfuvqYpIuB20kC4xnAfS1QNjNrz8qgF7tYJ83z7D5+8ZycfQH8uFSFMrP2T228dphFsbHYI1uyIGZWRtpBB0wWmUbSSBoLjAa61adFxM2lKpSZtXdtvwMmi0YDpKRLgeNIAuT9JDNq/Ilkskkzs/zKoAaZpRf7NJLxjn+NiK8ChwFdS1oqM2v/6jIubViWJvbWiKiTVCOpN8mca35Q3MwKa9qEuW1WlgA5T1If4NckPdvvAXNLWSgza//Kuhe7XkT8U7p6naTZJC+9eam0xTKzdq+cA6SkjxXbFxHzS1MkM7O2oVgN8soi+wI4oZnLkslrC3oyYf/xrXFpe58++dK7rV0Ea6JHPrL35yjrJnZEHN+SBTGzMhKU/VBDM7P3r5xrkGZme6Osm9hmZnulDAJklhnFJenLkn6Ybu8nyb0kZlZcB5lRfBpwNMlLuwE2AdeUrERm1u4psi+Zzif1kfQ7Sa9KekXS0ZL6SXpY0pL0s29O/kskVUlaLOmknPTDJS1I912tBu+zbihLgDwyIs4DtgFExEagS7avZWYdVp2yLdn8ApgdEYeQzAfxCnAxMCciRgFz0m0kjQYmAWOACcA0SZXpea4FpgCj0mVCsYtmCZA70pNHevGBtPkh5mbW2pqrBpnOAXEs8BuAiNgeEW8DE4EZabYZwKnp+kTg9oiojoilQBUwXtIQkpGAT0dEkMxIVn9MXlkC5NXAXcAgSVNJpjq7PMNxZtaRNd89yAOBtcB/SnpB0g2SegKDI2IVQPo5KM0/DFiec/yKNG1Yut4wvaAsY7F/K+l5kinPBJwaEa9k+lpm1jE14f4iMEDSvJzt6RExPWe7E/Ax4IKIeFbSL0ib0wXka7dHkfSCskyYux+wBbgnNy0iljV2rJl1YNkD5LqIOKLI/hXAioh4Nt3+HUmAXC1pSESsSpvPa3Lyj8g5fjiwMk0fnie9oCxN7PuAe9PPOcDrwAMZjjOzDkx12ZbGRMRfgeWSDk6TTgQWAbOAyWnaZODudH0WMElSV0kjSTpj5qbN8E2Sjkp7r8/KOSavLE3s3Yatp7P8nFMgu5lZKVwA/FZSF5JK2ldJKngzJZ0NLANOB4iIhZJmkgTRGuC8iKhNz3MucBPQnaSiV7Sy1+SRNBExX9LHm3qcmXUwzfgQeES8CORrhp9YIP9UYGqe9HnA2KzXzXIP8ts5mxUkN0vXZr2AmXVATeukabOy1CB75azXkNyL/H1pimNmZaPcA2T6gPg+EXFRC5XHzMpFOQdISZ0ioqbYqxfMzPIR2Xqo27piNci5JPcbX5Q0C7gD2Fy/MyLuLHHZzKy96kD3IPsB60neQVP/NHoADpBmVliZB8hBaQ/2y+w5TKcMvrqZlVQZRIliAbIS2If3MX7RzKzcm9irIuKyFiuJmZWXMg+Q7f+djWbWOqL8e7HzDuExM8uknGuQEbGhJQtiZuWl3O9Bmpm9fw6QZmZ5tINXumbhAGlmzU64iW1mVpADpJlZIQ6QZmYFOECameXRgWbzMTNrOgdIM7P8yn2ooZnZ++YmtplZPmXyoHhFaxfAzMpUZFwykPSGpAWSXpQ0L03rJ+lhSUvSz745+S+RVCVpsaSTctIPT89TJelqSUVnLXOANLNmVz+SJsvSBMdHxLiIOCLdvhiYExGjgDnpNpJGA5OAMcAEYFr6hlaAa4EpwKh0mVDsgg6QZlYSqotMy16YCMxI12cAp+ak3x4R1RGxFKgCxksaAvSOiKcjIoCbc47JywHSzJpf1uZ1Eh8HSJqXs0wpcMaHJD2fs39wRKwCSD8HpenDgOU5x65I04al6w3TC3InjZmVRBOaz+tyms2FHBMRKyUNAh6W9GqxS+dJa/jiwdz0glyDNLPSaMZOmohYmX6uAe4CxgOr02Yz6eeaNPsKYETO4cOBlWn68DzpBTlAmllJNFcnjaSeknrVrwOfIXkd9SxgcpptMnB3uj4LmCSpq6SRJJ0xc9Nm+CZJR6W912flHJOXm9hmVhrN9xzkYOCu9ImcTsCtETFb0nPATElnA8uA0wEiYqGkmcAioAY4LyJq03OdC9wEdAceSJeCHCDNrPk141sNI+J14LA86esp8HLBiJgKTM2TPg8Ym/XaDpBm1uw8o7iZWTHR/iOkA6SZlYRrkFbUgCHVXPTzpfQduIOog/tvHcjd//kBRn54Cxde/gbdetSxekUXfvLNg9jyXuXO4wYOrWb6Iy9zy1VD+f30IQB06lzHP122jEOPepeoEzf9dBhPPdCvtb5a2Xrrvyr5653Jb9FzVPChH++gomuyb8VNlSz9WWeO+uM2Ovfddcy2VfD8qV3Z/9wahn+llprN8NJXuuzcX71aDPpsLQf9S01LfpXWVSaTVZQsQEq6EfgcsCYi9rgpmnaz/wI4BdgCfCUi5peqPK2hrlb8+v+OoOrlnnTvWcsv713IC3/al2/9+1J+PXUEC57tzWe+sJbTzlnFzVfuejzrnB8uZ97j++52rknnr+Kd9Z342vGHIgW9+nSgf2wtpHo1vPXbSg7/w3Yqu8Er3+nM2tmVDJ5YS/VfYeMzFXQdsue/+td/0pl+f7OrR6JTT/jYHdt3br9wRhcGnFi7x3Hlrhzmgyzlc5A3UXwg+MnsGjA+hWQQeVnZsKYLVS/3BGDr5kqWV3Wn/+DtDDtwGwue7QXA/Cd7c8zJG3cec/RnNvLXZV1587Xuu53rpC+s5fZrktpkhHh3Y+cW+hYdS9SKumqIGqjbBl0GJgHxLz/pzMhv1ewxFmPdoxV0Gx70OCh/dWnrm2L7BtH78DKoTjWR6rItbVnJAmREPAFsKJJlInBzJJ4B+tQ/FV+OBg+v5qAxW1j84j68+Vp3jvr02wAc+9mNDByS1Da6dq/lC+eu4parhu52bM/eSW1x8nfe4lf3LeT706roM2BHi5a/I+g6GIZPrmHuZ7ryzIldqdwH+n6ijvWPVdB1ULDPwbsHudotsOLGTux/buHa/JoHKhh4Ui3FJ9UqQ0HSSZNlacNacyRNoQHle5A0pX4g+47Y1iKFa07detTyr9dVcf1lI9jyXiU/u2gkf3fWGn5570K696ylZkfyr+cfv/0Wd97wAbZtqdzt+MrKYODQHSyctw/nf3YMr8zfh69/f3m+S9le2PEurH+sgo8/UM2Rj1RTtxVWz6pg+a87sf95ewbBN6d1Ytg/1lDZo/A5186uZOApHa95DSWZ7qzFtWYnTeaB4xExHZgO0Luifxv/I91dZac6fnBdFY/9oT9PzU46VVb8pTvf/8eDARg2chvjT3gHgEPGbeaTJ2/ka5csp2fvWiJge3UF98wYxLYtFfz37KRn4In7+nLSGWtb5wuVsbefSZrLXdK+r/4n1rL67kq2vSXmn5701FSvhhfO6Mq4W6vZtKCCdY9UsvTnULMJJKjoCkPPTALie4sFtdBrdLv6K9t8yuBrt2aALDSgvIwE3/rJGyyr6s6dN3xgZ+q+/XfwzvrOSMGZF6zkvt8OBOA7p394Z54v//NbbN1SwT0zBgPwzCN9OPToTfz5v3vz0WM2sWzJ7vcobe91/UCw6aUKardCRTd4+9lK+p9Yx6G/2XU7Y+6Ernz0tmo694XDZuzqiHlzWicqe8TO4Aiw9oFKBk5o4zfZSsQPiu+9WcD5km4HjgTeqZ/brVyMOeI9PvW/1rP0le5cc//LANz0H8MZesA2/u6sZOKRp2b35aGZAxo9141XDOein7/ON364jLc3dOJn3xlZ0rJ3RL0PDQZ8qo4XzuiCKmGfDwdDTnv/zeN1D1YwZloHvVccez0ZbpugKNFNUkm3AccBA4DVwKVAZ4CIuC59zOdXJD3dW4CvpuMki+pd0T+O6lx0lnRrY/7m+XdbuwjWRJd+5N7nM8zRWFCvPsPjo8d+M1PeJ+/57l5dq5RKVoOMiDMb2R/AeaW6vpm1LjexzczyCaAMmtgOkGZWGu0/PjpAmllpuIltZlZAOfRiO0CaWfPzbD5mZvklD4q3/wjpAGlmpVEGg4gcIM2sJFyDNDPLp0zuQbbmdGdmVraSsdhZlqwkVUp6QdK96XY/SQ9LWpJ+9s3Je4mkKkmLJZ2Uk364pAXpvqvTIc8FOUCaWWk0/4S53wReydm+GJgTEaOAOek2kkYDk4AxJHM9TJNUP8nqtSRvMKh/m0HRiR0cIM2s+UXzvnJB0nDgs8ANOckTgRnp+gzg1Jz02yOiOiKWAlXA+PSNBb0j4ul0Loibc47Jy/cgzaw0stcOB0jKnclrejpJdq6rgO8CvXLSBtdPkRgRqyQNStOHAc/k5Kt/W8GOdL1hekEOkGZWGtlbz+uKTXcmqf7tqM9LOi7D+Qq9rSDzWwzqOUCaWUmortkehDwG+HtJpwDdgN6SbgFWSxqS1h6HAGvS/IXeVrAiXW+YXpDvQZpZ8wuSB8WzLI2dKuKSiBgeEQeQdL48GhFfJnkrweQ022Tg7nR9FjBJUldJI0k6Y+amzfFNko5Ke6/PyjkmL9cgzazZiWiJB8WvAGZKOhtYBpwOEBELJc0EFgE1wHkRUf/ujHOBm4DuwAPpUpADpJmVRgkCZEQ8Djyerq8HTiyQbyowNU/6PGBs1us5QJpZaXiooZlZHvX3INs5B0gzK4lm7MVuNQ6QZlYCTR5G2CY5QJpZ8wscIM3MCmr/LWwHSDMrDU+Ya2ZWiAOkmVkeEVDb/tvYDpBmVhquQZqZFeAAaWaWRwBNeN9MW+UAaWYlEBC+B2lmtqfAnTRmZgX5HqSZWQEOkGZm+XiyCjOz/ALwdGdmZgW4Bmlmlo+HGpqZ5RcQfg7SzKyAMhhJU9HaBTCzMhWRbWmEpG6S5kr6s6SFkv4tTe8n6WFJS9LPvjnHXCKpStJiSSflpB8uaUG672pJKnZtB0gza34RSS92lqVx1cAJEXEYMA6YIOko4GJgTkSMAuak20gaDUwCxgATgGmSKtNzXQtMAUaly4RiF3aANLPSaKYaZCTeSzc7p0sAE4EZafoM4NR0fSJwe0RUR8RSoAoYL2kI0Dsino6IAG7OOSYvB0gzK4EgamszLVlIqpT0IrAGeDgingUGR8QqgPRzUJp9GLA85/AVadqwdL1hekHupDGz5te06c4GSJqXsz09IqbvdrqIWmCcpD7AXZLGFjlfvvuKUSS9IAdIMyuN7I/5rIuIIzKdMuJtSY+T3DtcLWlIRKxKm89r0mwrgBE5hw0HVqbpw/OkF+Qmtpk1uwCiLjItjZE0MK05Iqk78CngVWAWMDnNNhm4O12fBUyS1FXSSJLOmLlpM3yTpKPS3uuzco7JyzVIM2t+0awT5g4BZqQ90RXAzIi4V9LTwExJZwPLgNOTS8dCSTOBRUANcF7aRAc4F7gJ6A48kC4FOUCaWUlk7YBp9DwRLwEfzZO+HjixwDFTgal50ucBxe5f7kbRzgaUS1oLvNna5SiRAcC61i6EZVbOv9f+ETHw/R4saTbJn08W6yKi6POIraXdBchyJmle1pvV1vr8e5U/d9KYmRXgAGlmVoADZNsyvfEs1ob49ypzvgdpZlaAa5BmZgU4QJqZFeAA2cIkTUgn8aySdHGe/Uon8qyS9JKkj7VGOS0h6UZJayS9XGC/f68y5gDZgtKhUtcAJwOjgTPTyT1zncyuyTynkEzwaa3nJopPqurfq4w5QLas8UBVRLweEduB20km98w1Ebg5nST0GaBPOlOJtYKIeALYUCSLf68y5gDZsgpN5NnUPNZ2+PcqYw6QLSvLhJ1NntTTWpV/rzLmANmyCk3k2dQ81nb49ypjDpAt6zlglKSRkrqQvHltVoM8s4Cz0t7Ro4B36t+7YW2Sf68y5vkgW1BE1Eg6H3gQqARuTCf3/Ea6/zrgfuAUkjexbQG+2lrlNZB0G3AcyXtTVgCXkrxVz79XB+ChhmZmBbiJbWZWgAOkmVkBDpBmZgU4QJqZFeAAaWZWgANkGZJUK+lFSS9LukNSj704102STkvXb8gzuUZu3uMkfeJ9XOMNSXu8Aa9QeoM87zXxWj+S9J2mltE6JgfI8rQ1IsZFxFhgO/CN3J3prEJNFhFfi4hFRbIcBzQ5QJq1VQ6Q5e9J4INp7e4xSbcCCyRVSvoPSc+l8xieAzvnN/yVpEWS7gMG1Z9I0uOSjkjXJ0iaL+nPkuZIOoAkEH8rrb1+UtJASb9Pr/GcpGPSY/tLekjSC5KuJ/945t1I+oOk5yUtlDSlwb4r07LMkTQwTTtI0uz0mCclHdIsf5rWoXgkTRmT1IlkvsLZadJ4YGxELE2DzDsR8XFJXYGnJD0EfBQ4GPgIMBhYBNzY4LwDgV8Dx6bn6hcRGyRdB7wXET9N890K/Dwi/iRpP5IRRB8mGY3yp4i4TNJnSeZRbMz/Tq/RHXhO0u8jYj3QE5gfEf9H0g/Tc59P8kKtb0TEEklHAtOAE97HH6N1YA6Q5am7pBfT9SeB35A0fedGxNI0/TPAofX3F4F9SSZ9PRa4LSJqgZWSHs1z/qOAJ+rPFRGF5kv8FDBa2llB7C2pV3qNz6fH3idpY4bvdKGkf0jXR6RlXQ/UAf8/Tb8FuFPSPun3vSPn2l0zXMNsNw6Q5WlrRIzLTUgDxebcJOCCiHiwQb5TaHy6LmXIA8ktnKMjYmuesmQe4yrpOJJge3REbJH0ONCtQPZIr/t2wz8Ds6byPciO60HgXEmdASR9SFJP4AlgUnqPcghwfJ5jnwb+VtLI9Nh+afomoFdOvodImruk+calq08AX0rTTgb6NlLWfYGNaXA8hKQGW68CqK8Ff5Gk6f4usFTS6ek1JOmwRq5htgcHyI7rBpL7i/OVvJDqepIWxV3AEmAByftV/tjwwIhYS3Lf8E5Jf2ZXE/ce4B/qO2mAC4Ej0k6gRezqTf834FhJ80ma+ssaKetsoJOkl4AfA8/k7NsMjJH0PMk9xsvS9C8BZ6flW8ier7Ywa5Rn8zEzK8A1SDOzAhwgzcwKcIA0MyvAAdLMrAAHSDOzAhwgzcwKcIA0MyvgfwBG1RGEeNYGiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(gnb, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc3135",
   "metadata": {},
   "source": [
    "# Results Analysis\n",
    "As we can see the accuracy when we assign 60% of the dataset to test and we use Naive Bayes model to predict the battle is around 75%, it means that we will predict correctly 3/4 of the battles.\n",
    "\n",
    "According to the confusion matrix, as we can see In row 0 there are 12607 points, but only 9773 are correctly allocated to 0 and 2834 are incorrectly assigned to 1. In row 1 there are 11393 points, but only 8447 are correctly allocated to 1 and 2946 are incorrectly apportioned to 0. It seems that the model prediction fails a little more when we expect win."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc186c17-b9e0-4ad6-82a9-6b638ab41d0d",
   "metadata": {},
   "source": [
    "## Part 4 (Optional) - Create an ensemble and configure the model\n",
    "\n",
    "You have trained different classifiers but selected only one of them as \"the best\" one. Maybe instead of having the models competing between them, having them to colaborate would yield better results. \n",
    "\n",
    "We propose you to create an ensemble of the different classifiers explored in *Part 3*. You should compare the ensemble with the individual models using cross-validation, and then get the final accuracy and the confusion matrix for the ensemble.\n",
    "As a bonus, try to tune the parameters of this ensemble using either `GridSearchCV` or `RandomizedSearchCV`.\n",
    "\n",
    "1. Train an ensemble with the classifiers in *Part 3*.\n",
    "2. Compare the performance of this ensemble using cross-validation, the final accuracy, and the confusion matrix. Analyze the results.\n",
    "3. Fine-tune the hyper-parameters of the ensemble using `GridSearchCV` or `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c194fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "\n",
      "Cross_Validation: [0.770625 0.75625  0.77875  0.75     0.748125 0.748125 0.739375 0.75125\n",
      " 0.7525   0.779375] \n",
      "\n",
      "Scores Mean: 0.7574375\n",
      "\n",
      "Final Accuracy: 0.7600416666666666\n",
      "\n",
      "[[9798 2809]\n",
      " [2950 8443]] : is the confusion matrix\n"
     ]
    }
   ],
   "source": [
    "# Ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print(\"Decision Tree Classifier:\\n\")\n",
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "scores = cross_val_score(tree_clf,X_train,y_train,cv=10)\n",
    "tree_y_pred = tree_clf.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "print(f\"Cross_Validation: {scores} \\n\\nScores Mean: {scores.mean()}\\n\")\n",
    "print(f\"Final Accuracy: {accuracy_score(y_test, tree_y_pred)}\\n\")\n",
    "print(confusion_matrix(y_test, tree_y_pred), \": is the confusion matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d417d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "\n",
      "Cross_Validation: [0.811875 0.81625  0.843125 0.798125 0.818125 0.82125  0.80375  0.811875\n",
      " 0.814375 0.8125  ] \n",
      "\n",
      "Scores Mean: 0.8151250000000001\n",
      "\n",
      "Final Accuracy: 0.8184166666666667\n",
      "\n",
      "[[10892  1715]\n",
      " [ 2643  8750]] : is the confusion matrix\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier:\\n\")\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(random_forest_clf,X_train,y_train,cv=10)\n",
    "random_forest_y_pred = random_forest_clf.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "print(f\"Cross_Validation: {scores} \\n\\nScores Mean: {scores.mean()}\\n\")\n",
    "print(f\"Final Accuracy: {accuracy_score(y_test, random_forest_y_pred)}\\n\")\n",
    "print(confusion_matrix(y_test, random_forest_y_pred), \": is the confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9fdb9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 16\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@senapati.dipak97/grid-search-vs-random-search-d34c92946318\n",
    "print(f\"Dimensions: {len(X.columns)}\")\n",
    "\n",
    "# Random search is the best parameter search technique when there are less number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a051bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(CV_rfc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca8a84c",
   "metadata": {},
   "source": [
    "As we can see, when we use an ensemble model the accuracy is better than the simple model, it is because the goal of ensemble methods is to combine the predictions of several base estimators, built with a given learning algorithm in order to improve generalizability / robustness over a single estimator. \n",
    "\n",
    "For this reason, when we use the Decision Tree Classifier it has around 73% of accuracy and the Random Forest Classifier it has around 79% of accuracy. Also, Random forest classifier is useful because:\n",
    "- No overfitting\n",
    "- High accuracy\n",
    "- Estimates missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2b144-ee23-4c6a-b8c8-4abf6e85dedb",
   "metadata": {},
   "source": [
    "## Part 5 - Wrap-up (2 points)\n",
    "The final part of this assignment is to wrap-up your classifier into a pipeline. This pipeline will execute the entire process:\n",
    "\n",
    "- Preprocess the data\n",
    "    - Select features\n",
    "    - Impute data\n",
    "    - Encode values\n",
    "- The classifier selected in *Part 3* (or the ensemble if it is better)\n",
    "\n",
    "This pipeline will be used in the other provided notebook to generate the predictions for the combats you have to submit.\n",
    "\n",
    "To ensure everything works as expected, we recommend you to load the dataset again before using it with the pipeline. You should also compare the accuracy and the confusion matrix from the pipeline with the model trained before. **Remember to set the random state to all the required transformers and estimators to have a constant output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f464b6bb-4f99-4671-ba66-5f8d93ee1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "processing_df = data\n",
    "processing_df['Wins'] = processing_df['Wins'].astype('Int64')\n",
    "processing_df = processing_df.drop(columns=['Legendary', 'Legendary__other','Generation','Generation__other','Type 2','Type 2__other'])\n",
    "\n",
    "cat = ['Name','Name__other','Type 1','Type 1__other']\n",
    "num = ['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed','HP__other', 'Attack__other', 'Defense__other', 'Sp. Atk__other', 'Sp. Def__other', 'Speed__other']\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"encode\", ColumnTransformer(transformers=[\n",
    "            (\"cat_name\", OneHotEncoder(sparse=False, handle_unknown = 'ignore'), cat)\n",
    "        ],remainder='passthrough')),\n",
    "        (\"imputer\", KNNImputer(n_neighbors=1)),\n",
    "        (\"classifier\", GaussianNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "524d9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_Xy(processing_df) # X = features , y = target (Win/Loss)\n",
    "\n",
    "y = y.astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=0)\n",
    "\n",
    "y_pred = clf.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2556a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9379 3228]\n",
      " [2195 9198]] : is the confusion matrix\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred), \": is the confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ec1b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7740416666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d09a1",
   "metadata": {},
   "source": [
    "First of all, the wrap-up has a little difference from the original development. The difference is that we drop all the useless columns before the KNN imputation. For this reason, the accuracy from the original is lower than the wrap-up.\n",
    "\n",
    "Original Accuracy : 75.91%\n",
    "Wrap-up Accuracy: 77.40%\n",
    "\n",
    "The wrap-up improves the prediction in the fourth quadrant in the confusion matrix. However, that improvement it is not important to conclude if this method is better than the original way, because the other quadrants are worse and the final accuracy is also better than original.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
